Based on https://www.youtube.com/watch?v=I7fdWafTcPY
https://raw.githubusercontent.com/johnthebrit/CertificationMaterials/main/whiteboards/AI-102-Whiteboard.png
https://learn.microsoft.com/en-us/credentials/certifications/azure-ai-engineer/?practice-assessment-type=certification#certification-practice-for-the-exam

1. Responsible AI
	- Fairness - ai system should treat all people the same, not beinn biased on gender, race etc.
	- Relability and Savety - vehicles etc has to be safe, regular testing
	- Privacy and security - models and data used to train them, np. our data in storage account shouldn't be used to train other shit
	- Inclusiveness - every part of society sholud be able to take advantage of this
	- Transparency - we shold now as much as possible how it work
	- Accountability - there should be framework that solution meets ethical, legal standards

2. What is AI
	Software that exhibits human-like abilities
	- Visual perception - understanding video, text etc.
	- Language - idea to use natural language processing, understanding semantic meaning
	- Speech - text to speech - speech to text, conversational AI
	- Decision making - treshold that triggers decision in my mind
	
	AI builds on top of machine learning.
	Machine learning - all data + algorithms used to train prediction models
	Machine learning is build on top of data science which is math and statistics used to analyse data.

3. Azure ML

	I have data that I have labeled. Data to traning and data to test. 
	Data -> train -> (create) model -> deploy model -> Data (feedback)

4. Azure Cognitive Services (Azure AI)

	Visual Perception:
		Image analysis (picture give me info about it).
		Video analysis (info about/from video)
		Image clasification
		Object detection (where is specifc object in image)
		Facial analysis
		OCR (optical character recognition)

	Language:
		Language understanding 
			Question-answering
			Text analysis
		Translation

	Speech:
		Speech to text
		Text to speech
		Speech translation
		Speaker recognition

	Decision making:
		Anomaly detection (f.e. temperature rising)
		Content moderation
		Content personalization (shopping cart)

	Prebuild solutions:
	- Forms recognizer
	- Metrics adviser
	- Video analyser for media
	- Image reader
	- BOT service (some kind of conversational interaction) - webchat, email interactions, teams and shit
	- Cognitive search 
		you have data your going to ingest to create an index and run diffrent types of search against this index to give result
		you can enrich the index

5. Deploying to Azure

	Azure Cognitive Services
	Provisioning service to subscription + region which give RESOURCE (Cognitive service resource)
	When provisioning use name (np. eastus)

	Resource can be:
		- multi-service
			it is a single restfull endpoint witch single access credential
		- single-service
		note: training might require diffrent resource

		- resource ma endpoint uri
		- Cognitive Services Account ma 2 klucze (account keY), mozna przegenerowywac 1 podczas uzycia 2giego itp.
		Klucze powinny byc persystowane w key vaulcie.
		Resourcy maja swoj firewall wiec mozna restrict access do nich (do np. konkretnych public IPs)
		Service endpoints i private endpoints

6. REST API and SDK

	Need to know:
	endpoint URI and Keys (best to read from keyVault)

	We are creating JSON paylod in http to the endpoint and it responds with another json data.

7. Pricing and monitoring

	Paid based on number of interactions.
	There is azure pricing calculator

	- metrics, alerts, logs, same as in S4D + integration with event hub

8. Deploying to container

	We can run model locally (on-premise) in container for example for safety requirements (car, fabryka roboty itp.)

	Microsoft Artifacts Registry - to persist this containers

	Owe docker image robimy based of 'from image' (based on Azure Cognitive Services image), do ktorych uruchomienia potrzebujemy:
	Billing.ApiKey,	BILLING.Endpoint URI, EULA (eula='accept') (End-User License Agreement)
	wymagane jest jakies połaczenie internetowe do raportowania tych rzeczy i zgody na EULA, 
	pobrania api keya, zeby autoryzowac sie poslugiwania servicami uruchomionymi lokalnie

9. Visual Perception Services

	Image analysis:
		Sending picture of car -> returns some info about it (f.e. image description)
		Można ten image skategoryzować, nadać mu tag (car, sun).
		Może też miec object Car: {X, Y, Height, Top}
		Mozna robic content moderation (filtrowac zdejcia przemoca), ratingowac zdjecia, robic celebrity recognition
		Mozna robic miniaturki

	Video analysis:
		Facial recognition (detecting presence of indiviudal people in image)
		OCR
		Speech transcription
		Key topics in the video
		it can have idea of: Sentiment (positive video, negative video)
		it can have idea of: Label - key themes, objects in the video
		content moderation, scene segmentation

		jesli chcemty rozpoznwaca ludzi, powinnismy miec Limited Access Approval

	Image Clasification:
		predict class label based on main subject of an image (vehicle, fruit, vegetable)
		We have to train it.
		Start with data (image) and label it -> train -> model 
		Send other images to model and in will predict its a car with some specs. It is multilabel

	Object detection
		Znajdowanie obiektow na image

	Facial Analysis
		Face service, ensure privacy of that information
		It will not say gender and not say age (it might be offensive for people - lol).
		Sa w 2 servicy, ktore moga pomoc z detekcja twarzy. General computer vision service (hey, yes there is a face i jest tutaj)
		i Face Service - go further - (yes there is a face and has some attributes, rozpoznaje nos, oczy, itp.)
		Face service (where it is, info about it, detection and verification)
		- Every face detection will have unique id and will be cached for 24h. (came in to building, left building)
		- Face recognition, sklada sie to z Person Group i image, ktore pozwalaja wytrenowac ta usluge do rozpoznawania konkretnych ludzi,
		that will be persisted

	OCR
		Znow sa 2 API do tego:
		Read API - (read from images, read from pdf, small to large volume (book/magazines)) -  main service to use, handle large volume shit
		Image Analysis API - (supported formats: JPEG, PNG, BMP, PDF, TIFF up to 2000 pages, less 500 MB)
			obsluguje 164 print languages, 9 languages for handwritten text

10. Language Understanding

	Idea of learned
		CLU (Custom language understading) - we have to train it on some INTENT (get time) which has possible 
			Utterences and related Entity (what time is it, tell me the time, what is the time in (entity): London
			Train -> test -> deploy -> review -> feedback Train
		Custom named entities (person, event, skill, value) - pass array of labels and give it entities in represent (training) - pass data as JSON
		Custom text classification (document text and classify to custom groups) 
			Single label - bunch of possible lables (L1, L2, L3, L4) and bunch of texts. Text has only 1 label
			Multi label - Text has multiple labels

	Idea of pre-configured
		Summarization (bunch of text -> key senteces about it)
		PII Detection (IP addresses, email, street addresses, health info, name detection itp.)

		About the learned - 2 important parameters:
		Recalll - of the actuall labels how many was identified? ratio true positives to all labeled.
			Imagine I search for "pizza" -> returned 4 docs, 3 correct, 1 was shit, there were 3 more good -> Recall = 3/6
		Precision - 3/4 (4 docs returned, 3 correct)

11. Questions answering and Text analysis

	a) Question answering

	About the pre-configured:
	
	We are going to create Knowledge Base based on files, online, chit-chat files, dbs. Then we can use from chat assistant
	It is implemented as:
	BOT -> Q to knowledge base -> Answer returned as JSON
		We can have `top` parameter for top 3 best answers.

	b) Text analysis

		Extract info from text. Features:

		- langugae detection
		- key phrase extraction
		- sentiment analysis
		- named entity recognition
		- entity linking

12. Translation

	Language detection
	One-to-many translation
	Transliteration - converting text from native script to alternative script (from 1 alphabet to diffrent alphabet)

13. Speech Services

	Speech to text
		config files:
		- SpeechConfig {location, key},  -> SpeechRecognizer, return text and duration of it
		- AudioConfig (instead of microphone some other shit)

	Text to speech
		config files:
		- SpeechConfig {location, key},  -> Speech synthesizer
		- AudioConfig (instead of microphone some other shit)
		- Audio format
		- Voices to use

		text to speech long audio api for whole book etc.

		We can feed it in text or in SSML (speech synthesis mockup language) - we can have speaking styles, intonation, voices etc.

14. Speech Translation
	
	Speech to text (original lang and translated text)
	Synthesize translations
		- event based 1:1 (1 input lang, 1 output lang)
		- manual 1:n 
		It has intent recognition (understand semantic meaning of spoken input)

15. Decision making

	Anomaly detection (2 types):
		- 1 signal
		- multi-signal

	Content moderation
		- work for both images and text

	Content personalization 
		- best decision (shopping cart idea)

16. Forms recognizer and other pre-build solutions

	JPEG, PNG, PDF, TIFF (500MB max) -> its returning json with text, selecion marks
	USefull for business cards, invoices, Id cards, receipts, w2 forms

	- Custom model
		Create forms based on trainin on with OCR, label etc. Sample data can be in blob container. 1x fields file (json) to train

	Other pre buiild solutions:
	- Metrics adviser
	- Video analyser for media
	- Imersive reader - make content available for anyone (easy to read for example, add pictures, hightlight shit, translate, read it, split to syllabells)
	- Bot service - conversational
	- Cognitive search

17. Bot service

	Chat gpt, persist context, input as text, image, speech

	Azure Bot Service
		Bot Framework Service [REST endpoint]
		Bot Framework SDK that calls rest endpoint
			Development against SDK

18. Azure Cognitive Service

	Cloud native solution for indexing data and quering based on huge amount of data.

	Data could be:
		- blob
		- database tables
		- cosmos db
		Data -> Azure Data Factory

		More opportunities like: extracting text from image and add it to language.

	Azure Cognitive Service Resource pricing tiers:
		(F)ree, (B)asic, (S)tandard, (L)arge

		Replicas to load balance queries to diffrent instances
			Inside replicas there are Partitions. Every replica will have the same number of partitions
		
		Search units = Replicas * Partitions

		More replicas = more resilience
		Microsoft guatrantees 99.9% avability:
		* 2 replicas for high availability read-only workloads
		* 3 or more replicas for high availability read-write workloads
		Search units max = 36

		Enrichment comes from skillset. Durign the enrichment (dodawanie nowych danych do indekosawania) 
		there might be created a PROJECTION into Knowledge Store (which is: JSON, table, file)

		Skillset -> we can create cusotm skill (azure function with uri), create custom skill with WebApiSkill property which points to Azure Func URI
	
19. Azure OpenAI Services

	LLM:
		- GPT 3.5 Turbo / 4.0
		- Embeddings -> to create vectors based on info
		- DALL-E -> to create pictures

	LLMs were trained on huge amounts of data.
	We can leverage instances of this module.

	The more specific the prompt -> the better response will be.

	User prompt and System prompt (for more info/context)
	Grounding prompt -> enhancing prompt

	Tweak how this model will response with Temperature and top probability (np. more artistic, more strict, more imaginatory)

	Grounding might add APIs to get data -> the model will work as orchestrator. We can add our own data.
	Your own data:
		- uploaded
		- blob
		- cognitive search index

----------------------------------------------------------------------------------------------------------------------------------
